{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification\n",
    "\n",
    "Reviewing some linear classification concepts. Here, I will use linear classification on the CIFAR-10 images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting classes\n",
    "\n",
    "Our linear classifier looks as follows:\n",
    "\n",
    "$$f(x_i, Wb) = Wx_i + b$$\n",
    "\n",
    "where $x_i$ are our inputs (images) and W the weights and b the biases.\n",
    "\n",
    "\n",
    "### Note on matrix shape\n",
    "\n",
    "Note that the CIFAR-10 has 10 classes. Therefore, for a given image, our function should give the probabilities that it belongs to each of these categories. \n",
    "\n",
    "Note that these images will be flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get One batch of CFAR 10 data set\n",
    "\n",
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    \"\"\"\n",
    "    Load a batch of the dataset\n",
    "    \"\"\"\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_cfar10_batch('../Udacity/deep_learning/projects/image-classification/cifar-10-batches-py',\n",
    "                 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = data[0]\n",
    "labels = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalizing image data\n",
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    x_min = x.min(axis=(1, 2), keepdims=True)\n",
    "    x_max = x.max(axis=(1, 2), keepdims=True)\n",
    "    return (x - x_min)/(x_max - x_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jose/anaconda/envs/data_science/lib/python3.4/site-packages/ipykernel/__main__.py:10: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "features = np.array([normalize(i) for i in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening one Image and going through one of these classifications\n",
    "\n",
    "Here, I will use one image as an example to understand how the matrix multiplication works and how, in the end, we have as output 10 classes.\n",
    "\n",
    "Note that our image has 32, 32, 3 shape. This means it has 32x32 pixels and and red, green, blue channels. As a first step, we flatten this image, resulting in a 1*3072 array.\n",
    "\n",
    "Note that we need to have corresponding weights for each of the pixels. That means that our weights matrix needs to have 3072 rows, one weight per each pixel and 10 columns, one per each classs. On top, we add a bias per class, that is, we add 10 bias. \n",
    "\n",
    "<img src=\"img/linear_class/matrix_mult_linear.png\" width=\"900px\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Flattening the image\n",
    "first_image = features[0]\n",
    "flatten_first = first_image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creating randomly our weights \n",
    "weights_matrix = np.random.standard_normal((3072, 10))\n",
    "bias = np.random.standard_normal(10)\n",
    "#Performing the dot product\n",
    "matrix_multiply = np.dot(flatten_first, weights_matrix) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our weights, outputs and images, we perform the dot product between the image and weights. This gives us a 1*10 array to which we then add the biases. In the end we have a 10 array which represents the \"scores\" given to each of the classes. We have reduced our 3072 array to a 10 array output thanks to our weights. \n",
    "\n",
    "However, we don't simply want to reduce the dimmensionality of our picture. We want to make sure than when we receive an image as an input, the right category is selected. This means that we need to train our weights to correctly perform such classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(matrix_multiply) / np.sum(np.exp(matrix_multiply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:data_science]",
   "language": "python",
   "name": "conda-env-data_science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

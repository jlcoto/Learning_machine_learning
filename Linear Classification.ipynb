{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Linear Classification\n",
    "\n",
    "Reviewing some linear classification concepts. Here, I will use linear classification on the CIFAR-10 images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Predicting classes\n",
    "\n",
    "Our linear classifier looks as follows:\n",
    "\n",
    "$$f(x_i, Wb) = Wx_i + b$$\n",
    "\n",
    "where $x_i$ are our inputs (images) and W the weights and b the biases.\n",
    "\n",
    "\n",
    "### Note on matrix shape\n",
    "\n",
    "Note that the CIFAR-10 has 10 classes. Therefore, for a given image, our function should give the probabilities that it belongs to each of these categories. \n",
    "\n",
    "Note that these images will be flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Get One batch of CFAR 10 data set\n",
    "\n",
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    \"\"\"\n",
    "    Load a batch of the dataset\n",
    "    \"\"\"\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = load_cfar10_batch('../Udacity/deep_learning/projects/image-classification/cifar-10-batches-py',\n",
    "                 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = data[0]\n",
    "labels = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def image_standarization(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    x_demean = x - np.mean(x)\n",
    "    adjusted_sd = np.maximum(np.std(x), 1.0/np.sqrt(np.prod(x.shape)))\n",
    "    return  x_demean / adjusted_sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = np.array([image_standarization(i) for i in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flattening one Image and going through one of these classifications\n",
    "\n",
    "Here, I will use one image as an example to understand how the matrix multiplication works and how, in the end, we have as output 10 classes.\n",
    "\n",
    "Note that our image has 32, 32, 3 shape. This means it has 32x32 pixels and and red, green, blue channels. As a first step, we flatten this image, resulting in a 1*3072 array.\n",
    "\n",
    "Note that we need to have corresponding weights for each of the pixels. That means that our weights matrix needs to have 3072 rows, one weight per each pixel and 10 columns, one per each classs. On top, we add a bias per class, that is, we add 10 bias. \n",
    "\n",
    "<img src=\"img/linear_class/matrix_mult_linear.png\" width=\"900px\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Flattening the image\n",
    "first_image = features[0]\n",
    "flatten_first = first_image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Creating randomly our weights \n",
    "weights_matrix = np.random.standard_normal((3072, 10))\n",
    "bias = np.zeros(10)\n",
    "#Performing the dot product\n",
    "matrix_multiply = np.dot(flatten_first, weights_matrix) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Once we have our weights, outputs and images, we perform the dot product between the image and weights. This gives us a 1*10 array to which we then add the biases. In the end we have a 10 array which represents the \"scores\" given to each of the classes. We have reduced our 3072 array to a 10 array output thanks to our weights. \n",
    "\n",
    "However, we don't simply want to reduce the dimmensionality of our picture. We want to make sure than when we receive an image as an input, the right category is selected. This means that we need to train our weights to correctly perform such classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9467491471520559e-22"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization trick for numerical stability\n",
    "matrix_multiply -= np.max(matrix_multiply)\n",
    "# Applying Softmax to our reduced dimension matrix\n",
    "soft_max = np.exp(matrix_multiply) / np.sum(np.exp(matrix_multiply))\n",
    "soft_max[np.argmax(labels[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluating our Weights\n",
    "\n",
    "Once we have perform this matrix multiplication, and push it through a softmax function, is evaluation time. The label that our weights predict, would be the class that has the biggest probability.\n",
    "\n",
    "According to our results, this corresponds to the automobile label. However, the true label corresponds to an airplane. Why the mistake? Simple, our linear classifier has yet to learn. It has started with random weights, therefore, the output will also be random. Here is where the *learning* part of machine learning starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred_label = np.argmax(soft_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels_names = 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "labels_dict = dict(enumerate(labels_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict[pred_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict[labels[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Learning Weights\n",
    "\n",
    "We need to come up with a way of telling our algorithm that it is wrong to classify an airplane as a car. This is where loss functions come into play. Loss functions will measure how much off is our algorithm from the real labels. Loss functions will increase the more difference between predictions and algorithms. The objective is to reduce the loss function. Is from this process of trial and error that our algorithm learns better weights.\n",
    "\n",
    "The loss function for the softmax has the following form:\n",
    "\n",
    "$$L_i = -log \\Big(\\frac{e^{f_{y_i}}}{\\sum_je^{f_j}}\\Big)$$\n",
    "\n",
    "Note that $i$ refers to the correct class. In this case we want to increase our loss function in relation with how well it does at classifying the true label.\n",
    "\n",
    "Let's put an example: suppose we have only three classes to classify: \"car\", \"pen\", \"house\". \n",
    "\n",
    "<img src=\"img/linear_class/softmax.png\" width=\"750px\">\n",
    "\n",
    "In the figure we show the effect after our images have gone through the weights and a softmax function has been applied. As shown, even if the car is the correct label, it only gets a probability of 0.1. Correspondingly, we calculate the loss for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025850929940455"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Loss\n",
    "ex_softmax = np.array([0.1, 0.5, 0.4])\n",
    "true_label = [1, 0, 0]\n",
    "#Getting the calculated softmax for correct label\n",
    "i_loss = np.dot(ex_softmax, true_label)\n",
    "loss = -np.log(i_loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As the calculation reflects, our loss increases, because our prediction is incorrect. It is interesting to show how the softmax changes due to changes in the probability assigned to the right label. To start with, it is important to notice that a logarithm of a small number will be big, the smaller the number, the bigger the result. On the other extreme, $log(1) = 0$. This calculation goes with our intuition. It says, when the right label has a small probability, then you need to add to the loss. On the other hand when there is a probability of 1 on the correct label, there is no need to add to the loss, because the classifier has it right.\n",
    "\n",
    "Here is a graph for our example on how the loss changes given the probabilities assigned to the right label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAElCAYAAAALP/6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fb53208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generating different probabilities for correct label\n",
    "y = np.arange(0.00001, 1, 0.01)\n",
    "sim = -np.log(np.arange(0.00001, 1, 0.01))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y, sim);\n",
    "ax.set_title(\"Decreasing of Loss as \\nProbability of correct label Increases\")\n",
    "ax.set_ylabel(\"Loss value\")\n",
    "ax.set_xlabel(\"Probability of Correct Label\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The loss is important because it will guide us in our objective. In particular, we want to make the loss as small as possible. However, what steps do we need to take to make sure we are decreasing the loss. After all, there is a bunch of weights that can be consider. How to make sure we are actually going in the direction of minimizing the loss? \n",
    "\n",
    "Here is where calculus kicks in. Finding the gradient of the loss with respect to the weights makes sure that everytime we update our weights we are doing it in the direction that minimizes the loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Updating weights after one gradient descent for first image\n",
    "#One hot encoding labels\n",
    "image_cat = list(range(0,10))\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(image_cat)\n",
    "labels = encoder.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#For one pass\n",
    "#Getting softmax of correct label\n",
    "soft_max[np.argmax(labels[0])] -= 1\n",
    "dsoft = soft_max\n",
    "dW = np.outer(flatten_first, dsoft)\n",
    "db = np.sum(dsoft, axis=0, keepdims=True)\n",
    "weights_matrix -= 0.5 * dW\n",
    "bias[0] -= 0.5 *db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see the changes for our example for one pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_multiply = np.dot(flatten_first, weights_matrix) + bias\n",
    "matrix_multiply -= np.max(matrix_multiply)\n",
    "soft_max = np.exp(matrix_multiply) / np.sum(np.exp(matrix_multiply))\n",
    "soft_max[np.argmax(labels[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our calculations for this image made the weights to properly predict the label. The story is more complicated when more image and labels are to be trained. In this case, there is a lot of trade-offs to be done, and our classifier is bound to make some mistakes. Let's do three things: \n",
    "1. Split our data set in training/validation/testing.\n",
    "2. Train our weights with our training data and then check validation error.\n",
    "3. Test our parameters on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Flattening all images\n",
    "features = features.reshape(10000, 32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image, image_test, y, y_test = train_test_split(features,labels,test_size=0.2,train_size=0.8)\n",
    "image_train, image_val, y_train, y_val = train_test_split(image, y,test_size = 0.25,train_size =0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(features, weights):\n",
    "    matrix_multiply = np.dot(features, weights) + bias\n",
    "    exp = np.exp(matrix_multiply) \n",
    "    soft_max = exp / np.sum(exp, axis=1, keepdims=True)\n",
    "    return soft_max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2846163888484794\n",
      "Validation Accuracy: 0.8563\n",
      "Loss: 2.2674336269140962\n",
      "Validation Accuracy: 0.8568\n",
      "Loss: 2.251447491862663\n",
      "Validation Accuracy: 0.8569\n",
      "Loss: 2.236556120632148\n",
      "Validation Accuracy: 0.8574\n",
      "Loss: 2.2096901380587832\n",
      "Validation Accuracy: 0.8577\n",
      "Loss: 2.1975507158152436\n",
      "Validation Accuracy: 0.8576\n",
      "Loss: 2.18617560615842\n",
      "Validation Accuracy: 0.8576\n",
      "Loss: 2.1754994254573985\n",
      "Validation Accuracy: 0.8576\n",
      "Loss: 2.1560116449626188\n",
      "Validation Accuracy: 0.8583\n",
      "Loss: 2.1470971949402267\n",
      "Validation Accuracy: 0.8584\n",
      "Loss: 2.138675071056721\n",
      "Validation Accuracy: 0.8587\n",
      "Loss: 2.1307051110346933\n",
      "Validation Accuracy: 0.8591\n",
      "Loss: 2.115979569487773\n",
      "Validation Accuracy: 0.8594\n",
      "Loss: 2.1091611498544176\n",
      "Validation Accuracy: 0.8596\n",
      "Loss: 2.1026685849994236\n",
      "Validation Accuracy: 0.8593\n",
      "Loss: 2.09647729870283\n",
      "Validation Accuracy: 0.8599\n",
      "Loss: 2.084911341633739\n",
      "Validation Accuracy: 0.8607\n",
      "Loss: 2.079497948569199\n",
      "Validation Accuracy: 0.8611\n",
      "Loss: 2.0743080029727183\n",
      "Validation Accuracy: 0.8615\n",
      "Loss: 2.069326195669973\n",
      "Validation Accuracy: 0.8616\n",
      "Loss: 2.0599323159540375\n",
      "Validation Accuracy: 0.8616\n",
      "Loss: 2.0554957984825895\n",
      "Validation Accuracy: 0.8617\n",
      "Loss: 2.0512183042854986\n",
      "Validation Accuracy: 0.8619\n",
      "Loss: 2.0470900201117876\n",
      "Validation Accuracy: 0.862\n",
      "Loss: 2.0392457530961057\n",
      "Validation Accuracy: 0.8626\n",
      "Loss: 2.0355138469277128\n",
      "Validation Accuracy: 0.8629\n",
      "Loss: 2.0318991744167634\n",
      "Validation Accuracy: 0.8629\n",
      "Loss: 2.028395234733484\n",
      "Validation Accuracy: 0.8628\n",
      "Loss: 2.0216959549268037\n",
      "Validation Accuracy: 0.8634\n",
      "Loss: 2.0184898891098957\n",
      "Validation Accuracy: 0.8638\n",
      "Loss: 2.0153730291044867\n",
      "Validation Accuracy: 0.8638\n",
      "Loss: 2.0123409222431\n",
      "Validation Accuracy: 0.864\n",
      "Loss: 2.0065146736634163\n",
      "Validation Accuracy: 0.8645\n",
      "Loss: 2.0037130669322134\n",
      "Validation Accuracy: 0.8647\n",
      "Loss: 2.0009812382817587\n",
      "Validation Accuracy: 0.8647\n",
      "Loss: 1.9983160397449822\n",
      "Validation Accuracy: 0.865\n",
      "Loss: 1.9931739273015092\n",
      "Validation Accuracy: 0.8654\n",
      "Loss: 1.9906916574135958\n",
      "Validation Accuracy: 0.8653\n",
      "Loss: 1.9882652781415895\n",
      "Validation Accuracy: 0.8654\n",
      "Loss: 1.9858924985818722\n",
      "Validation Accuracy: 0.8655\n",
      "Loss: 1.981299236016356\n",
      "Validation Accuracy: 0.8656\n",
      "Loss: 1.9790748033647063\n",
      "Validation Accuracy: 0.8657\n",
      "Loss: 1.976896053813027\n",
      "Validation Accuracy: 0.866\n",
      "Loss: 1.9747612764973794\n",
      "Validation Accuracy: 0.8658\n",
      "Loss: 1.9706172510163802\n",
      "Validation Accuracy: 0.8664\n",
      "Loss: 1.96860501845688\n",
      "Validation Accuracy: 0.8665\n",
      "Loss: 1.9666307781338976\n",
      "Validation Accuracy: 0.8668\n",
      "Loss: 1.9646932227916654\n",
      "Validation Accuracy: 0.8669\n",
      "Loss: 1.9609232607522193\n",
      "Validation Accuracy: 0.8671\n",
      "Loss: 1.9590885499957873\n",
      "Validation Accuracy: 0.8674\n",
      "Loss: 1.9572859086431718\n",
      "Validation Accuracy: 0.8675\n",
      "Loss: 1.9555143174613516\n",
      "Validation Accuracy: 0.8675\n",
      "Loss: 1.9520604425589094\n",
      "Validation Accuracy: 0.8672\n",
      "Loss: 1.9503763459250834\n",
      "Validation Accuracy: 0.867\n",
      "Loss: 1.9487196685456663\n",
      "Validation Accuracy: 0.8668\n",
      "Loss: 1.9470896014378973\n",
      "Validation Accuracy: 0.8668\n",
      "Loss: 1.9439062351975445\n",
      "Validation Accuracy: 0.8673\n",
      "Loss: 1.942351485404064\n",
      "Validation Accuracy: 0.8676\n",
      "Loss: 1.940820441005324\n",
      "Validation Accuracy: 0.8678\n",
      "Loss: 1.939312449637632\n",
      "Validation Accuracy: 0.868\n",
      "Loss: 1.9363631470718476\n",
      "Validation Accuracy: 0.8679\n",
      "Loss: 1.9349206575698232\n",
      "Validation Accuracy: 0.8678\n",
      "Loss: 1.93349886195552\n",
      "Validation Accuracy: 0.8678\n",
      "Loss: 1.9320972266694814\n",
      "Validation Accuracy: 0.8679\n",
      "Loss: 1.9293524029565057\n",
      "Validation Accuracy: 0.868\n",
      "Loss: 1.9280082445502649\n",
      "Validation Accuracy: 0.868\n",
      "Loss: 1.9266823046712531\n",
      "Validation Accuracy: 0.8679\n",
      "Loss: 1.9253741413639807\n",
      "Validation Accuracy: 0.8682\n",
      "Loss: 1.9228094546067163\n",
      "Validation Accuracy: 0.8683\n",
      "Loss: 1.9215521230213162\n",
      "Validation Accuracy: 0.8683\n",
      "Loss: 1.9203109503752782\n",
      "Validation Accuracy: 0.8681\n",
      "Loss: 1.9190855663984345\n",
      "Validation Accuracy: 0.8682\n",
      "Loss: 1.916680744938576\n",
      "Validation Accuracy: 0.8684\n",
      "Loss: 1.9155006268456392\n",
      "Validation Accuracy: 0.8685\n",
      "Loss: 1.9143349351803929\n",
      "Validation Accuracy: 0.8687\n",
      "Loss: 1.9131833565343308\n",
      "Validation Accuracy: 0.869\n",
      "Loss: 1.9109213339084976\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.9098103111132005\n",
      "Validation Accuracy: 0.869\n",
      "Loss: 1.9087122429286758\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.907626861613216\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.9054931284737437\n",
      "Validation Accuracy: 0.8691\n",
      "Loss: 1.9044442800635109\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.903407124750785\n",
      "Validation Accuracy: 0.8688\n",
      "Loss: 1.902381431891867\n",
      "Validation Accuracy: 0.8688\n",
      "Loss: 1.900363543563032\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.8993709186661114\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.8983888969017086\n",
      "Validation Accuracy: 0.8688\n",
      "Loss: 1.8974172780833585\n",
      "Validation Accuracy: 0.8689\n",
      "Loss: 1.8955044754799788\n",
      "Validation Accuracy: 0.869\n",
      "Loss: 1.8945629176793222\n",
      "Validation Accuracy: 0.869\n",
      "Loss: 1.8936310144249182\n",
      "Validation Accuracy: 0.8692\n",
      "Loss: 1.8927085907810197\n",
      "Validation Accuracy: 0.8692\n",
      "Loss: 1.8908915050519135\n",
      "Validation Accuracy: 0.8694\n",
      "Loss: 1.8899965151012588\n",
      "Validation Accuracy: 0.8697\n",
      "Loss: 1.8891103487364842\n",
      "Validation Accuracy: 0.8697\n",
      "Loss: 1.888232852146002\n",
      "Validation Accuracy: 0.8698\n",
      "Loss: 1.886503271944095\n",
      "Validation Accuracy: 0.8699\n",
      "Loss: 1.8856508992392986\n",
      "Validation Accuracy: 0.8699\n",
      "Loss: 1.8848066178856255\n",
      "Validation Accuracy: 0.8699\n",
      "Loss: 1.8839702918915024\n",
      "Validation Accuracy: 0.8699\n",
      "Loss: 1.8823209780432328\n",
      "Validation Accuracy: 0.8701\n",
      "Loss: 1.881507733931383\n",
      "Validation Accuracy: 0.8702\n",
      "Loss: 1.8807019324716017\n",
      "Validation Accuracy: 0.8703\n",
      "Loss: 1.8799034528211451\n",
      "Validation Accuracy: 0.8703\n",
      "Loss: 1.8783279892666318\n",
      "Validation Accuracy: 0.8705\n",
      "Loss: 1.8775507771193334\n",
      "Validation Accuracy: 0.8705\n",
      "Loss: 1.8767804301374542\n",
      "Validation Accuracy: 0.8704\n",
      "Loss: 1.8760168404479425\n",
      "Validation Accuracy: 0.8707\n",
      "Loss: 1.8745095132248912\n",
      "Validation Accuracy: 0.8709\n",
      "Loss: 1.8737655715124637\n",
      "Validation Accuracy: 0.8707\n",
      "Loss: 1.873027978604541\n",
      "Validation Accuracy: 0.8706\n",
      "Loss: 1.872296637804801\n",
      "Validation Accuracy: 0.8709\n",
      "Loss: 1.8708523359288562\n",
      "Validation Accuracy: 0.8709\n",
      "Loss: 1.8701391914748047\n",
      "Validation Accuracy: 0.8709\n",
      "Loss: 1.8694319322649013\n",
      "Validation Accuracy: 0.8709\n",
      "Loss: 1.8687304712924366\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.8673446048945204\n",
      "Validation Accuracy: 0.8708\n",
      "Loss: 1.8666600341752522\n",
      "Validation Accuracy: 0.8708\n",
      "Loss: 1.8659809310149054\n",
      "Validation Accuracy: 0.8708\n",
      "Loss: 1.865307216853589\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.863975649039433\n",
      "Validation Accuracy: 0.8711\n",
      "Loss: 1.8633176458980585\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.86266473270188\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.862016838291856\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.8607358280062303\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.860102576523066\n",
      "Validation Accuracy: 0.871\n",
      "Loss: 1.8594740725456786\n",
      "Validation Accuracy: 0.8711\n",
      "Loss: 1.8588502514297063\n",
      "Validation Accuracy: 0.8711\n",
      "Loss: 1.8576164052180324\n",
      "Validation Accuracy: 0.8713\n",
      "Loss: 1.8570062567603138\n",
      "Validation Accuracy: 0.8713\n",
      "Loss: 1.8564005443841785\n",
      "Validation Accuracy: 0.8715\n",
      "Loss: 1.8557992092045084\n",
      "Validation Accuracy: 0.8715\n",
      "Loss: 1.85460944022414\n",
      "Validation Accuracy: 0.8715\n",
      "Loss: 1.8540208939087353\n",
      "Validation Accuracy: 0.8715\n",
      "Loss: 1.8534364997124042\n",
      "Validation Accuracy: 0.8715\n",
      "Loss: 1.8528562038615661\n",
      "Validation Accuracy: 0.8714\n",
      "Loss: 1.8517076968440258\n",
      "Validation Accuracy: 0.8713\n",
      "Loss: 1.8511393828078175\n",
      "Validation Accuracy: 0.8713\n",
      "Loss: 1.850574961336617\n",
      "Validation Accuracy: 0.8713\n",
      "Loss: 1.8500143832100475\n",
      "Validation Accuracy: 0.8714\n",
      "Loss: 1.8489045643426822\n",
      "Validation Accuracy: 0.8716\n",
      "Loss: 1.8483552293387178\n",
      "Validation Accuracy: 0.8716\n",
      "Loss: 1.847809549117031\n",
      "Validation Accuracy: 0.8717\n",
      "Loss: 1.847267478526749\n",
      "Validation Accuracy: 0.8717\n",
      "Loss: 1.8461939894283508\n",
      "Validation Accuracy: 0.8717\n",
      "Loss: 1.8456624843612925\n",
      "Validation Accuracy: 0.8718\n",
      "Loss: 1.8451344157763385\n",
      "Validation Accuracy: 0.872\n",
      "Loss: 1.8446097421711354\n",
      "Validation Accuracy: 0.872\n",
      "Loss: 1.8435704172962486\n",
      "Validation Accuracy: 0.872\n",
      "Loss: 1.8430556863849785\n",
      "Validation Accuracy: 0.872\n",
      "Loss: 1.8425441911427607\n",
      "Validation Accuracy: 0.8721\n",
      "Loss: 1.842035893347771\n",
      "Validation Accuracy: 0.8721\n",
      "Loss: 1.841028740279774\n",
      "Validation Accuracy: 0.8721\n",
      "Loss: 1.840529811593317\n",
      "Validation Accuracy: 0.8722\n",
      "Loss: 1.8400339335029863\n",
      "Validation Accuracy: 0.8722\n",
      "Loss: 1.8395410707445317\n",
      "Validation Accuracy: 0.8723\n",
      "Loss: 1.8385642529363964\n",
      "Validation Accuracy: 0.8724\n",
      "Loss: 1.8380802300953911\n",
      "Validation Accuracy: 0.8725\n",
      "Loss: 1.837599086982252\n",
      "Validation Accuracy: 0.8726\n",
      "Loss: 1.8371207910058114\n",
      "Validation Accuracy: 0.8727\n"
     ]
    }
   ],
   "source": [
    "## Algorithm\n",
    "epochs = 200\n",
    "n_training = len(image_train)\n",
    "step_size = 0.001\n",
    "\n",
    "#Initializing weights and biases\n",
    "weights_matrix = 0.0001*np.random.standard_normal((3072, 10))\n",
    "bias = np.zeros((1,10))\n",
    "#Performing the dot product\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    #Perform dot product \n",
    "    soft_max = score(image_train, weights_matrix)\n",
    "\n",
    "\n",
    "    #Calculating Loss\n",
    "    correct_labels_prob = soft_max[range(n_training), np.argmax(y_train, axis=1)]\n",
    "    loss = np.sum(-np.log(correct_labels_prob)) / n_training\n",
    "    \n",
    "    \n",
    "    #Calculating gradient\n",
    "    g_probs = np.copy(soft_max)\n",
    "    g_probs[range(n_training), np.argmax(y_train, axis=1)] -= 1\n",
    "    \n",
    "    #Get the average of the gradients\n",
    "    g_probs = g_probs / n_training\n",
    "    \n",
    "    dW = np.dot(image_train.T, g_probs)\n",
    "    db = np.sum(g_probs, axis=0, keepdims=True)\n",
    "    \n",
    "    # perform a parameter update\n",
    "    weights_matrix += -step_size * dW\n",
    "    bias += -step_size * db\n",
    "    \n",
    "    if i%5:\n",
    "        print(\"Loss: {}\".format(loss))\n",
    "\n",
    "    # evaluate training set accuracy\n",
    "    preds_score = score(image_val, weights_matrix)\n",
    "    pred_ones = np.zeros_like(preds_score) #generates zero matrix to populate them with ones to then make comparisons\n",
    "    pred_ones[np.arange(len(preds_score)), preds_score.argmax(1)] = 1\n",
    "    accuracy = np.mean(pred_ones == y_val)\n",
    "\n",
    "    if i%5:\n",
    "        print(\"Validation Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Notes from Stanford's CNN's for visual recognition](http://cs231n.github.io/neural-networks-case-study/)\n",
    "\n",
    "[Deriving the softmax loss](https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:data_science]",
   "language": "python",
   "name": "conda-env-data_science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
